import json
import os
import cv2
import numpy as np
from collections import Counter, defaultdict
import shutil  # æ–°å¢ï¼šç”¨æ–¼åˆªé™¤æª”æ¡ˆ
import re  # æ–°å¢ï¼šç”¨æ–¼ extract_base_video_name

def is_valid_video(video_path, min_duration=2, max_duration=15):
    """æª¢æŸ¥å½±ç‰‡æ˜¯å¦æœ‰æ•ˆï¼ˆé•·åº¦åœ¨ min-max ä¹‹é–“ï¼‰"""
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        return False
    
    fps = cap.get(cv2.CAP_PROP_FPS)
    frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    cap.release()
    
    if fps <= 0 or frames <= 0:
        return False
    
    duration = frames / fps
    return min_duration <= duration <= max_duration

def detect_aspect_ratio(video_path):
    """æª¢æ¸¬å½±ç‰‡æ¯”ä¾‹"""
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        return "unknown"
    
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    cap.release()
    
    if width == 0 or height == 0:
        return "unknown"
    
    aspect_ratio = width / height
    
    if abs(aspect_ratio - 16/9) < 0.1:
        return "16:9"
    elif abs(aspect_ratio - 4/3) < 0.1:
        return "4:3"
    elif abs(aspect_ratio - 1) < 0.1:
        return "1:1"
    elif abs(aspect_ratio - 936/480) < 0.1:
        return "936:480"
    elif abs(aspect_ratio - 1136/480) < 0.1:
        return "1136:480"
    else:
        return "other"

def extract_base_video_name(filename):
    """
    æå–å½±ç‰‡çš„åŸºç¤åç¨±,å»é™¤ç‰‡æ®µç·¨è™Ÿ
    ä¾‹å¦‚:
    - yutaka_nakamura_123_001.mp4 -> yutaka_nakamura_123
    - video_part1.mp4 -> video
    - animation_01.mp4 -> animation
    """
    # ç§»é™¤å‰¯æª”å
    name = os.path.splitext(filename)[0]
    
    # å˜—è©¦åŒ¹é…å¸¸è¦‹çš„ç‰‡æ®µæ¨¡å¼
    patterns = [
        r'(.+)_\d{3}$',           # name_001, name_002
        r'(.+)_part\d+$',         # name_part1, name_part2
        r'(.+)_segment\d+$',      # name_segment1
        r'(.+)-\d+$',             # name-1, name-2
        r'(.+)_\d+$',             # name_1, name_2
    ]
    
    for pattern in patterns:
        match = re.match(pattern, name, re.IGNORECASE)
        if match:
            return match.group(1)
    
    # å¦‚æœæ²’æœ‰åŒ¹é…åˆ°,è¿”å›åŸåç¨±
    return name

def scan_and_add_missing_videos(video_dir, feature_dir, metadata_path, min_duration=2, max_duration=60):
    """
    æƒæ test-videos è³‡æ–™å¤¾ï¼Œæ‰¾éºæ¼çš„è¦–é »ï¼ˆ.npy å­˜åœ¨ä½† metadata æ²’è¨˜éŒ„ï¼‰ï¼Œè£œå› metadata.json
    
    Args:
        video_dir: test-videos æ ¹ç›®éŒ„ (e.g., 'C:\\Users\\litsu\\Desktop\\sakuga\\test-videos')
        feature_dir: ç‰¹å¾µç›®éŒ„ (e.g., './features')
        metadata_path: metadata.json è·¯å¾‘
        min_duration, max_duration: é•·åº¦éæ¿¾
    
    Returns:
        bool: æ˜¯å¦æˆåŠŸè£œåŠ 
    """
    if not os.path.exists(metadata_path):
        print(f"âŒ metadata.json ä¸å­˜åœ¨: {metadata_path}")
        return False
    
    # è¼‰å…¥ç¾æœ‰ metadata
    with open(metadata_path, 'r', encoding='utf-8') as f:
        metadata = json.load(f)
    
    # ç¾æœ‰ feature_files é›†åˆï¼ˆç”¨æ–¼æ¯”å°éºæ¼ï¼‰
    existing_features = set()
    for animator, info in metadata.get('animators', {}).items():
        existing_features.update(info.get('feature_files', []))
    
    print(f"ğŸ“Š ç¾æœ‰ metadata è¨˜éŒ„ .npy: {len(existing_features)} å€‹")
    
    # æƒæ video_dirï¼ŒæŒ‰è³‡æ–™å¤¾åˆ†é¡
    animator_videos = defaultdict(list)  # {animator: [video_paths]}
    for root, dirs, files in os.walk(video_dir):
        animator = os.path.basename(root)
        if not animator:  # æ ¹ç›®éŒ„è·³é
            continue
        video_files = [f for f in files if f.lower().endswith(('.mp4', '.avi', '.mov', '.mkv'))]
        for video_file in video_files:
            video_path = os.path.join(root, video_file)
            animator_videos[animator].append(video_path)
    
    print(f"ğŸ” æƒæç™¼ç¾ {sum(len(paths) for paths in animator_videos.values())} å€‹è¦–é » (åˆ†é¡: {list(animator_videos.keys())})")
    
    # æ¯”å°ä¸¦è£œåŠ éºæ¼
    added_count = 0
    valid_feature_names = set(existing_features)  # æœ€çµ‚æœ‰æ•ˆå
    aspect_stats = Counter()
    
    for animator, video_paths in animator_videos.items():
        info = metadata.get('animators', {}).get(animator)
        if info is None:
            info = {
                'video_count': 0,
                'video_paths': [],
                'feature_files': [],
                'aspect_ratios': {},
                'video_groups': {},
                'added_date': str(np.datetime64('now'))
            }

        new_video_paths = []
        new_feature_files = []
        new_aspect_ratios = {}
        new_video_groups = {}
        current_feature_files = set(info.get('feature_files', []))
        
        new_video_paths = []
        new_feature_files = []
        new_aspect_ratios = {}
        new_video_groups = {}
        
        for video_path in video_paths:
            video_name = os.path.basename(video_path)
            feature_file = os.path.splitext(video_name)[0] + '.npy'
            feature_path = os.path.join(feature_dir, feature_file)
            
            # æª¢æŸ¥: .npy å­˜åœ¨ ä¸” ä¸åœ¨ç¾æœ‰ metadata
            if os.path.exists(feature_path) and feature_file not in existing_features:
                # æª¢æŸ¥é•·åº¦æœ‰æ•ˆ
                if is_valid_video(video_path, min_duration, max_duration):
                    # è£œåŠ 
                    new_video_paths.append(video_path)
                    new_feature_files.append(feature_file)
                    valid_feature_names.add(feature_file)
                    
                    # ç®— aspect
                    aspect = detect_aspect_ratio(video_path)
                    new_aspect_ratios[video_name] = aspect
                    aspect_stats[aspect] += 1
                    
                    # ç®— group
                    base_name = extract_base_video_name(video_name)
                    new_video_groups[video_name] = base_name
                    
                    added_count += 1
                    print(f"âœ… è£œåŠ éºæ¼: {feature_file} (animator: {animator}, é•·åº¦ OK)")
                else:
                    print(f"âš ï¸ éºæ¼ä½†é•·åº¦ç„¡æ•ˆ: {video_name} (animator: {animator})")
            else:
                if not os.path.exists(feature_path):
                    print(f"âš ï¸ .npy ä¸å­˜åœ¨: {feature_file} (animator: {animator})")
                # å·²åœ¨ metadataï¼Œè·³é
        
        # åˆä½µåˆ°ç¾æœ‰
        if new_video_paths:
            if animator not in metadata['animators']:
                print(f"ğŸ†• æ–°å‹•ç•«å¸«: {animator} (æ–°å¢ {len(new_video_paths)} å€‹å½±ç‰‡)")
                metadata['animators'][animator] = info
            info['video_paths'].extend(new_video_paths)
            info['feature_files'].extend(new_feature_files)
            info['aspect_ratios'].update(new_aspect_ratios)
            info['video_groups'].update(new_video_groups)
            info['video_count'] += len(new_video_paths)
            print(f"  {animator}: è£œåŠ  {len(new_video_paths)} å€‹æ–°æ¢ç›®")
    
    # æ›´æ–°ç¸½è¨ˆ
    metadata['video_count'] = sum(info['video_count'] for info in metadata['animators'].values())
    metadata['feature_count'] = len(valid_feature_names)
    metadata['last_valid_update'] = str(np.datetime64('now'))
    
    # ä¿å­˜
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æƒæè£œåŠ å®Œæˆ: æ–°å¢ {added_count} å€‹éºæ¼æ¢ç›®")
    print(f"ğŸ“Š æ–° video_count: {metadata['video_count']}")
    print(f"ğŸ“Š æ¯”ä¾‹çµ±è¨ˆ (æ–°å¢):")
    for ratio, count in aspect_stats.items():
        print(f"  {ratio}: {count} å€‹å½±ç‰‡")
    
    return True

def fix_metadata(metadata_path, feature_dir, min_duration=2, max_duration=60, clean_extra_npy=True, skip_duration_check=False, restore_from_backup=False):
    """
    ä¿®æ­£ metadata.jsonï¼Œåªä¿ç•™æœ‰æ•ˆå½±ç‰‡ï¼ˆé•·åº¦ 2-15s + å­˜åœ¨ .npyï¼‰
    
    Args:
        metadata_path: metadata.json è·¯å¾‘
        feature_dir: ç‰¹å¾µç›®éŒ„
        min_duration: æœ€å°é•·åº¦
        max_duration: æœ€å¤§é•·åº¦
        clean_extra_npy: æ˜¯å¦åˆªé™¤å¤šé¤˜ .npyï¼ˆé è¨­ Trueï¼‰
        skip_duration_check: æ˜¯å¦è·³éé•·åº¦æª¢æŸ¥ï¼ˆé è¨­ Falseï¼›è¨­ True ä¿ç•™çŸ­è¦–é »ï¼‰
        restore_from_backup: æ˜¯å¦å¾ backup æ¢å¾©å¤šé¤˜ .npyï¼ˆé è¨­ Falseï¼‰
    
    Returns:
        bool: æ˜¯å¦æˆåŠŸä¿®æ­£
    """
    if not os.path.exists(metadata_path):
        print(f"âŒ metadata.json ä¸å­˜åœ¨: {metadata_path}")
        return False
    
    # è¼‰å…¥ metadata
    with open(metadata_path, 'r', encoding='utf-8') as f:
        metadata = json.load(f)
    
    print(f"ğŸ“Š åŸå§‹ video_count: {metadata.get('video_count', 0)}")
    if skip_duration_check:
        print("âš ï¸  è·³éé•·åº¦æª¢æŸ¥ï¼ˆä¿ç•™æ‰€æœ‰çŸ­è¦–é »ï¼‰")
    
    updated_animators = {}
    total_valid_videos = 0
    removed_count = 0
    aspect_stats = Counter()
    
    # æ”¶é›†æ‰€æœ‰æœ‰æ•ˆ feature_filesï¼ˆç”¨æ–¼æ¯”å°å¤šé¤˜ .npyï¼‰
    valid_feature_names = set()
    
    for animator, info in metadata.get('animators', {}).items():
        valid_video_paths = []
        valid_feature_files = []
        valid_aspect_ratios = {}
        valid_video_groups = {}
        
        # å‡è¨­ video_paths å’Œ feature_files å°æ‡‰
        video_paths = info.get('video_paths', [])
        feature_files = info.get('feature_files', [])
        
        for i, (video_path, feature_file) in enumerate(zip(video_paths, feature_files)):
            video_name = os.path.basename(video_path)
            
            # æª¢æŸ¥ 1: å½±ç‰‡æœ‰æ•ˆï¼ˆé•·åº¦ï¼‰ - å¯è·³é
            if not skip_duration_check:
                if not is_valid_video(video_path, min_duration, max_duration):
                    removed_count += 1
                    print(f"è·³éç„¡æ•ˆé•·åº¦: {video_name} (animator: {animator})")
                    continue
            
            # æª¢æŸ¥ 2: ç‰¹å¾µæª”æ¡ˆå­˜åœ¨
            feature_path = os.path.join(feature_dir, feature_file)
            if not os.path.exists(feature_path):
                removed_count += 1
                print(f"è·³éç„¡ .npy: {feature_file} (animator: {animator})")
                continue
            
            # ä¿ç•™
            valid_video_paths.append(video_path)
            valid_feature_files.append(feature_file)
            valid_feature_names.add(feature_file)  # æ”¶é›†ç”¨æ–¼æ¯”å°
            
            # é‡æ–°ç®— aspectï¼ˆå¦‚æœèˆŠçš„ unknownï¼Œé‡ç®—ï¼‰
            old_aspect = info.get('aspect_ratios', {}).get(video_name, "unknown")
            if old_aspect == "unknown":
                aspect = detect_aspect_ratio(video_path)
                print(f"é‡ç®— aspect: {video_name} -> {aspect}")
            else:
                aspect = old_aspect
            valid_aspect_ratios[video_name] = aspect
            aspect_stats[aspect] += 1
            
            # ä¿ç•™ group
            base_name = extract_base_video_name(video_name)
            valid_video_groups[video_name] = base_name
        
        # æ›´æ–° info
        updated_info = {
            'video_count': len(valid_video_paths),
            'video_paths': valid_video_paths,
            'feature_files': valid_feature_files,
            'aspect_ratios': valid_aspect_ratios,
            'video_groups': valid_video_groups,
            'added_date': info.get('added_date')  # ä¿ç•™èˆŠè³‡è¨Š
        }
        updated_animators[animator] = updated_info
        total_valid_videos += len(valid_video_paths)
    
    # æ›´æ–°ç¸½è¨ˆ
    metadata['animators'] = updated_animators
    metadata['video_count'] = total_valid_videos
    metadata['feature_count'] = total_valid_videos  # å‡è¨­æ¯å€‹æœ‰æ•ˆéƒ½æœ‰ .npy
    metadata['last_valid_update'] = str(np.datetime64('now'))  # æ¨™è¨˜å·²æ›´æ–°
    
    # ä¿å­˜
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ä¿®æ­£å®Œæˆ: ä¿ç•™ {total_valid_videos} å€‹æœ‰æ•ˆå½±ç‰‡ï¼Œç§»é™¤ {removed_count} å€‹ç„¡æ•ˆ")
    print(f"ğŸ“Š æ–° video_count: {total_valid_videos}")
    print(f"ğŸ“Š æ¯”ä¾‹çµ±è¨ˆ:")
    for ratio, count in aspect_stats.items():
        print(f"  {ratio}: {count} å€‹å½±ç‰‡")
    
    # æª¢æŸ¥å¯¦éš› .npy æ•¸
    all_npy_files = [f for f in os.listdir(feature_dir) if f.endswith('.npy')]
    actual_npy_count = len(all_npy_files)
    print(f"ğŸ“Š å¯¦éš› .npy æª”æ¡ˆ: {actual_npy_count}")
    
    # ### è™•ç†å¤šé¤˜ .npy
    extra_npy_count = actual_npy_count - total_valid_videos
    if extra_npy_count > 0:
        print(f"âš ï¸  ç™¼ç¾ {extra_npy_count} å€‹å¤šé¤˜ .npyï¼ˆmetadata æ²’è¨˜éŒ„çš„ï¼‰")
        
        extra_npy_files = [f for f in all_npy_files if f not in valid_feature_names]
        print(f"å¤šé¤˜æª”æ¡ˆç¤ºä¾‹: {extra_npy_files[:5]}...")  # åªå°å‰5
        
        if clean_extra_npy:
            backup_dir = os.path.join(feature_dir, 'backup_extra_npy')
            os.makedirs(backup_dir, exist_ok=True)
            
            deleted_count = 0
            for extra_file in extra_npy_files:
                src = os.path.join(feature_dir, extra_file)
                dst = os.path.join(backup_dir, extra_file)
                shutil.move(src, dst)  # ç§»åˆ° backupï¼Œé¿å…èª¤åˆª
                deleted_count += 1
                if deleted_count <= 10:  # é™å°ï¼Œé¿å…åˆ·å±
                    print(f"ç§»åˆ°å‚™ä»½: {extra_file}")
            
            print(f"âœ… å·²ç§» {deleted_count} å€‹å¤šé¤˜ .npy åˆ° {backup_dir}")
            print(f"ğŸ“Š ç›®éŒ„ç¾åœ¨ .npy: {total_valid_videos}")
        else:
            print("ğŸ’¡ è¨­ clean_extra_npy=True ä¾†è‡ªå‹•æ¸…ç†ï¼ˆç§»åˆ°å‚™ä»½ï¼‰")
    else:
        print("âœ… .npy æ•¸èˆ‡ metadata ä¸€è‡´ï¼Œç„¡å¤šé¤˜")
    
    # ### æ–°å¢ï¼šå¾ backup æ¢å¾©ï¼ˆå¦‚æœè¨­ Trueï¼‰
    if restore_from_backup:
        backup_dir = os.path.join(feature_dir, 'backup_extra_npy')
        if os.path.exists(backup_dir):
            restored_count = 0
            for file in os.listdir(backup_dir):
                if file.endswith('.npy'):
                    src = os.path.join(backup_dir, file)
                    dst = os.path.join(feature_dir, file)
                    shutil.move(src, dst)
                    restored_count += 1
                    print(f"æ¢å¾©å¾å‚™ä»½: {file}")
            print(f"âœ… å·²æ¢å¾© {restored_count} å€‹ .npy å¾ backup")
        else:
            print("â„¹ï¸  ç„¡ backup ç›®éŒ„ï¼Œè·³éæ¢å¾©")
    
    return True


# ä½¿ç”¨ç¯„ä¾‹
if __name__ == '__main__':
    metadata_path = './features/metadata.json'  # ä¿®æ”¹ç‚ºä½ çš„è·¯å¾‘
    feature_dir = './features' # ä½ çš„ config.feature_dir
    video_dir = r'C:\Users\litsu\Desktop\sakuga\test-videos'  # æ–°å¢ï¼šè¦–é »æ ¹ç›®éŒ„
    
    # å…ˆæƒæè£œåŠ éºæ¼
    scan_and_add_missing_videos(video_dir, feature_dir, metadata_path, min_duration=1)  # é™ä½ min=1ï¼Œä¿ç•™çŸ­ç‰‡
    
    # å†ä¿®æ­£éæ¿¾ç„¡æ•ˆï¼ˆè·³éé•·åº¦æª¢æŸ¥ï¼Œä¿ç•™è£œåŠ çš„ï¼‰
    fix_metadata(metadata_path, feature_dir, min_duration=2, skip_duration_check=True, clean_extra_npy=True, restore_from_backup=False)