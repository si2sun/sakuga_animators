import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import numpy as np
from tqdm import tqdm
import json
from configs.base_config import BaseConfig

# ç„¦é»æå¤±å‡½æ•¸
class FocalLoss(nn.Module):
    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction

    def forward(self, inputs, targets):
        if self.alpha is not None and isinstance(self.alpha, (list, np.ndarray)):
            self.alpha = torch.tensor(self.alpha, device=inputs.device)
        
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = (1 - pt) ** self.gamma * ce_loss
        
        if self.alpha is not None:
            focal_loss = self.alpha[targets] * focal_loss
        
        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        return focal_loss

# çŸ¥è­˜è’¸é¤¾æå¤±
class KDLoss(nn.Module):
    def __init__(self, temperature=2.0, lambda_kd=1.0):
        super(KDLoss, self).__init__()
        self.temperature = temperature
        self.lambda_kd = lambda_kd

    def forward(self, student_logits, teacher_logits, labels=None, old_classes=None):
        if old_classes is not None:
            student_old = student_logits[:, old_classes]
            teacher_old = teacher_logits[:, old_classes]
        else:
            student_old = student_logits
            teacher_old = teacher_logits

        kd_loss = F.kl_div(
            F.log_softmax(student_old / self.temperature, dim=1),
            F.softmax(teacher_old / self.temperature, dim=1),
            reduction='batchmean'
        ) * (self.temperature ** 2)

        return self.lambda_kd * kd_loss

# TCN + BiLSTM æ™‚é–“å·ç©ç¶²è·¯
class TemporalConvNet(nn.Module):
    def __init__(self, input_dim, output_dim, num_layers=3, dropout=0.3, lstm_hidden_dim=256, edge_dim=64):
        super(TemporalConvNet, self).__init__()
        self.edge_dim = edge_dim
        self.core_dim = input_dim - edge_dim
        
        self.layers = nn.ModuleList()
        dilations = [1, 2, 4, 8]
        
        for i in range(num_layers):
            dilation = dilations[i] if i < len(dilations) else dilations[-1]
            layer = nn.Sequential(
                nn.Conv1d(input_dim, input_dim, kernel_size=3, 
                         dilation=dilation, padding=dilation),
                nn.BatchNorm1d(input_dim),
                nn.ReLU(),
                nn.Dropout(dropout)
            )
            self.layers.append(layer)
        
        self.bilstm = nn.LSTM(
            input_size=input_dim,
            hidden_size=lstm_hidden_dim,
            num_layers=1,
            bidirectional=True,
            batch_first=True,
            dropout=0
        )
        
        self.classifier = nn.Sequential(
            nn.Linear(lstm_hidden_dim * 2, 512),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(512, output_dim)
        )
    
    def forward(self, x):
        batch_size, seq_len, feature_dim = x.shape
        
        x_tcn = x.transpose(1, 2)
        for layer in self.layers:
            residual = x_tcn
            x_tcn = layer(x_tcn)
            if x_tcn.shape == residual.shape:
                x_tcn = x_tcn + residual
        
        x_lstm = x_tcn.transpose(1, 2)
        lstm_out, _ = self.bilstm(x_lstm)
        global_feature = lstm_out.mean(dim=1)
        output = self.classifier(global_feature)
        return output, global_feature

# ç‰¹å¾µæ¯”å°æ¨¡å¡Š
class FeatureMatchingModule(nn.Module):
    def __init__(self, feature_dim=1344, num_classes=10, edge_dim=64):
        super(FeatureMatchingModule, self).__init__()
        self.feature_dim = feature_dim
        self.edge_dim = edge_dim
        self.core_dim = feature_dim - edge_dim
        self.num_classes = num_classes
        
        self.class_prototypes = nn.Parameter(
            torch.randn(num_classes, feature_dim)
        )
        nn.init.xavier_uniform_(self.class_prototypes)
        
        self.temperature = nn.Parameter(torch.tensor(0.07))
        
        self.core_projection = nn.Sequential(
            nn.Linear(self.core_dim, self.core_dim),
            nn.ReLU(),
            nn.Linear(self.core_dim, self.core_dim)
        )
        self.edge_projection = nn.Sequential(
            nn.Linear(self.edge_dim, self.edge_dim),
            nn.ReLU(),
            nn.Linear(self.edge_dim, self.edge_dim)
        )
    
    def forward(self, features):
        batch_size, seq_len, feature_dim = features.shape
        video_feature = features.mean(dim=1)
        
        core_features = video_feature[:, :self.core_dim]
        edge_features = video_feature[:, self.core_dim:]
        
        projected_core = self.core_projection(core_features)
        projected_edge = self.edge_projection(edge_features)
        projected_feature = torch.cat([projected_core, projected_edge], dim=1)
        
        projected_feature = F.normalize(projected_feature, p=2, dim=1)
        prototypes = F.normalize(self.class_prototypes, p=2, dim=1)
        
        similarity = torch.mm(projected_feature, prototypes.t())
        similarity = similarity / self.temperature
        
        return similarity, projected_feature

# æ··åˆæ¨¡å‹
class HybridFeatureTCNModel(nn.Module):
    def __init__(self, config, num_classes, edge_dim=64):
        super(HybridFeatureTCNModel, self).__init__()
        self.config = config
        self.num_classes = num_classes
        self.edge_dim = edge_dim
        self.core_dim = 1280
        
        self.tcn = TemporalConvNet(
            input_dim=self.core_dim + self.edge_dim,
            output_dim=num_classes,
            num_layers=3,
            dropout=0.3,
            lstm_hidden_dim=config.lstm_hidden_dim,
            edge_dim=self.edge_dim
        )
        
        self.feature_matching = FeatureMatchingModule(
            feature_dim=self.core_dim + self.edge_dim,
            num_classes=num_classes,
            edge_dim=self.edge_dim
        )
        
        self.fusion_weight = nn.Parameter(torch.tensor([0.6, 0.4]))
        
        self.fusion_classifier = nn.Sequential(
            nn.Linear(config.lstm_hidden_dim * 2 + (self.core_dim + self.edge_dim), 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )
    
    def forward(self, x, return_features=False):
        tcn_logits, tcn_features = self.tcn(x)
        matching_logits, matching_features = self.feature_matching(x)
        
        weights = F.softmax(self.fusion_weight, dim=0)
        weighted_logits = weights[0] * tcn_logits + weights[1] * matching_logits
        
        combined_features = torch.cat([tcn_features, matching_features], dim=1)
        fusion_logits = self.fusion_classifier(combined_features)
        
        final_logits = 0.5 * weighted_logits + 0.5 * fusion_logits
        
        if return_features:
            return final_logits, {
                'tcn_logits': tcn_logits,
                'matching_logits': matching_logits,
                'tcn_features': tcn_features,
                'matching_features': matching_features,
                'fusion_weights': weights
            }
        
        return final_logits

class FeatureDataset(Dataset):
    def __init__(self, feature_samples, label_to_idx, mode='train'):
        self.feature_samples = feature_samples
        self.label_to_idx = label_to_idx
        self.mode = mode
    
    def __len__(self):
        return len(self.feature_samples)
    
    def __getitem__(self, idx):
        feature_path, label = self.feature_samples[idx]
        features = np.load(feature_path, allow_pickle=True)
        
        if len(features.shape) == 1:
            features = features.reshape(1, -1)
        
        label_idx = self.label_to_idx[label]
        return torch.FloatTensor(features), torch.tensor(label_idx)

def collate_fn_dynamic(batch):
    features_list, labels_list = zip(*batch)
    max_len = max(f.shape[0] for f in features_list)
    
    padded_features = []
    for features in features_list:
        if len(features.shape) == 1:
            features = features.unsqueeze(0)
        
        seq_len = features.shape[0]
        if seq_len < max_len:
            # â­â­â­ æ¢å¤ä¸ºä½¿ç”¨æœ€åä¸€å¸§å¡«å…… (å®‰å…¨!) â­â­â­
            last_frame = features[-1:]
            padding = last_frame.repeat(max_len - seq_len, 1)
            padded = torch.cat([features, padding], dim=0)
        else:
            padded = features
        padded_features.append(padded)
    
    features_batch = torch.stack(padded_features)
    labels_list = torch.tensor(labels_list, dtype=torch.long) # ç¡®ä¿ labels æ˜¯ long ç±»å‹
    
    return features_batch, labels_list

class ModelTrainer:
    def __init__(self, config, data_manager, use_incremental=False,use_kd=False, replay_ratio=0.0, 
                 lambda_kd=1.0, kd_temperature=2.0, head_warmup_epochs=0, 
                 new_animators=None, use_kd_only=False, early_stopping_patience=5, 
                 early_stopping_min_delta=0.001, early_stopping_monitor='test_acc'):
        self.config = config
        self.data_manager = data_manager
        self.use_incremental = use_incremental
        self.use_kd_only = use_kd_only
        self.replay_ratio = replay_ratio
        self.lambda_kd = lambda_kd
        self.kd_temperature = kd_temperature
        self.head_warmup_epochs = head_warmup_epochs
        self.new_animators = new_animators
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # Early Stopping åƒæ•¸
        self.early_stopping_patience = early_stopping_patience
        self.early_stopping_min_delta = early_stopping_min_delta
        self.early_stopping_monitor = early_stopping_monitor
        self.best_metric = -float('inf') if early_stopping_monitor == 'test_acc' else float('inf')
        self.epochs_without_improvement = 0
        
        # è¨­ç½®æ–°èˆŠé¡åˆ¥
        self.old_animators = None
        self.old_num_classes = 0
        if self.new_animators:
            all_animators = set(self.data_manager.label_to_idx.keys())
            self.old_animators = sorted(list(all_animators - set(self.new_animators)))
            self.old_num_classes = len(self.old_animators)
        
        # æ–°å¢ï¼šç‚ºå¼±é¡åˆ¥è¨­ç½® FocalLoss çš„ alpha æ¬Šé‡
        self.class_weights = None
        if self.new_animators:
            num_classes = self.data_manager.get_num_classes()
            self.class_weights = [1.0] * num_classes  # é è¨­æ¬Šé‡ 1.0
            for animator in self.new_animators:
                idx = self.data_manager.label_to_idx[animator]
                self.class_weights[idx] = 2.0  # å¼±é¡åˆ¥æ¬Šé‡ x2
            print(f"âš–ï¸ é¡åˆ¥æ¬Šé‡: {self.class_weights}")
        
        self.teacher_model = None
        if self.use_incremental or self.use_kd_only:
            teacher_path = os.path.join(self.config.model_dir, 'teacher_model.pth')
            if os.path.exists(teacher_path):
                self.load_teacher_model(teacher_path)
            else:
                print("âš ï¸ æœªæ‰¾åˆ° teacher æ¨¡å‹ï¼ŒKD å°‡è‡ªå‹•ç¦ç”¨")
                if self.use_kd_only:
                    self.use_kd_only = False
                if self.use_incremental:
                    print("   âš ï¸ Incremental æ¨¡å¼å°‡åƒ…ä½¿ç”¨ Replayï¼Œä¸ä½¿ç”¨ KD")
        
    def load_teacher_model(self, teacher_path):
        checkpoint = torch.load(teacher_path, map_location=self.device)
        teacher_num_classes = checkpoint['num_classes']
        self.teacher_model = HybridFeatureTCNModel(
            self.config, teacher_num_classes, edge_dim=checkpoint.get('edge_dim', 64)
        ).to(self.device)
        self.teacher_model.load_state_dict(checkpoint['model_state_dict'])
        self.teacher_model.eval()
        print(f"âœ… è¼‰å…¥ Teacher æ¨¡å‹: {teacher_path}, é¡åˆ¥æ•¸: {teacher_num_classes}")

    def initialize_model(self, num_classes, load_pretrained=False):
        """
        åˆå§‹åŒ–æ¨¡å‹
        
        Args:
            num_classes: ç•¶å‰çš„é¡åˆ¥æ•¸ï¼ˆå¯èƒ½æ¯”é è¨“ç·´æ¨¡å‹å¤šï¼‰
            load_pretrained: æ˜¯å¦è¼‰å…¥é è¨“ç·´æ¬Šé‡
        """
        model = HybridFeatureTCNModel(self.config, num_classes).to(self.device)
        
        if load_pretrained and (self.use_incremental or self.use_kd_only):
            pretrained_path = os.path.join(self.config.model_dir, 'best_model.pth')
            if os.path.exists(pretrained_path):
                print(f"ğŸ”„ è¼‰å…¥é è¨“ç·´æ¨¡å‹: {pretrained_path}")
                checkpoint = torch.load(pretrained_path, map_location=self.device)
                
                # ç²å–èˆŠæ¨¡å‹çš„é¡åˆ¥æ•¸
                old_num_classes = checkpoint.get('num_classes', self.old_num_classes)
                print(f"   èˆŠæ¨¡å‹é¡åˆ¥æ•¸: {old_num_classes}, æ–°æ¨¡å‹é¡åˆ¥æ•¸: {num_classes}")
                
                if old_num_classes == num_classes:
                    # é¡åˆ¥æ•¸ç›¸åŒï¼Œç›´æ¥è¼‰å…¥
                    model.load_state_dict(checkpoint['model_state_dict'])
                    print(f"   âœ… å®Œæ•´è¼‰å…¥æ¨¡å‹æ¬Šé‡")
                else:
                    # é¡åˆ¥æ•¸ä¸åŒï¼Œåªè¼‰å…¥å…¼å®¹çš„å±¤ï¼ˆè·³éåˆ†é¡é ­ï¼‰
                    model_dict = model.state_dict()
                    pretrained_dict = checkpoint['model_state_dict']
                    
                    # éœ€è¦è·³éçš„å±¤ï¼ˆåŒ…å«é¡åˆ¥æ•¸çš„å±¤ï¼‰
                    skip_keys = [
                        'tcn.classifier.3.weight',           # TCN æœ€å¾Œä¸€å±¤
                        'tcn.classifier.3.bias',
                        'feature_matching.class_prototypes', # åŸå‹å‘é‡
                        'fusion_classifier.3.weight',        # Fusion æœ€å¾Œä¸€å±¤
                        'fusion_classifier.3.bias'
                    ]
                    
                    # éæ¿¾æ‰ä¸å…¼å®¹çš„å±¤
                    compatible_dict = {}
                    skipped_keys = []
                    
                    for k, v in pretrained_dict.items():
                        if k in skip_keys:
                            skipped_keys.append(k)
                            continue
                        
                        # æª¢æŸ¥å½¢ç‹€æ˜¯å¦åŒ¹é…
                        if k in model_dict and v.shape == model_dict[k].shape:
                            compatible_dict[k] = v
                        else:
                            skipped_keys.append(k)
                    
                    # è¼‰å…¥å…¼å®¹çš„æ¬Šé‡
                    model_dict.update(compatible_dict)
                    model.load_state_dict(model_dict)
                    
                    print(f"   âœ… è¼‰å…¥ {len(compatible_dict)}/{len(pretrained_dict)} å±¤")
                    print(f"   âš ï¸  è·³é {len(skipped_keys)} å€‹ä¸å…¼å®¹å±¤ï¼ˆå°‡éš¨æ©Ÿåˆå§‹åŒ–ï¼‰:")
                    for key in skipped_keys[:5]:  # åªé¡¯ç¤ºå‰5å€‹
                        print(f"      - {key}")
                    if len(skipped_keys) > 5:
                        print(f"      ... é‚„æœ‰ {len(skipped_keys) - 5} å€‹")
                    
                    # ç‰¹åˆ¥è™•ç†ï¼šæ“´å±• class_prototypesï¼ˆå¦‚æœéœ€è¦ï¼‰
                    if 'feature_matching.class_prototypes' in pretrained_dict:
                        old_prototypes = pretrained_dict['feature_matching.class_prototypes']
                        old_classes, feature_dim = old_prototypes.shape
                        
                        if old_classes < num_classes:
                            # ä¿ç•™èˆŠé¡åˆ¥çš„åŸå‹ï¼Œæ–°é¡åˆ¥éš¨æ©Ÿåˆå§‹åŒ–
                            new_prototypes = model.feature_matching.class_prototypes.data
                            new_prototypes[:old_classes] = old_prototypes
                            print(f"   ğŸ”„ æ“´å±• class_prototypes: {old_classes} â†’ {num_classes}")
            else:
                print(f"   âš ï¸  æœªæ‰¾åˆ°é è¨“ç·´æ¨¡å‹: {pretrained_path}")
        
        criterion = FocalLoss(alpha=self.class_weights, gamma=2.0)
        return model, criterion

    def create_data_loaders(self):
        train_samples, test_samples = self.data_manager.get_fixed_split_samples()
        
        if self.use_incremental:
            if self.replay_ratio > 0 and self.old_animators:
                old_samples = [(path, label) for path, label in train_samples 
                              if label in self.old_animators]
                num_old_samples = len(old_samples)
                num_replay = int(num_old_samples * self.replay_ratio)
                np.random.seed(42)
                replay_indices = np.random.choice(num_old_samples, num_replay, replace=False)
                replay_samples = [old_samples[i] for i in replay_indices]
                
                new_samples = [(path, label) for path, label in train_samples 
                              if label in self.new_animators]
                train_samples = replay_samples + new_samples
                print(f"ğŸ“Š Replay: ä½¿ç”¨ {len(replay_samples)} å€‹èˆŠæ¨£æœ¬ + {len(new_samples)} å€‹æ–°æ¨£æœ¬")

        train_dataset = FeatureDataset(train_samples, self.data_manager.label_to_idx, mode='train')
        test_dataset = FeatureDataset(test_samples, self.data_manager.label_to_idx, mode='test')

        train_loader = DataLoader(
            train_dataset,
            batch_size=self.config.batch_size,
            shuffle=True,
            collate_fn=collate_fn_dynamic,
            num_workers=0
        )
        test_loader = DataLoader(
            test_dataset,
            batch_size=self.config.batch_size,
            shuffle=False,
            collate_fn=collate_fn_dynamic,
            num_workers=0
        )
        return train_loader, test_loader

    def train_epoch(self, model, data_loader, optimizer, criterion, stage='joint'):
        model.train()
        total_loss = 0
        correct = 0
        total = 0

        kd_loss_fn = KDLoss(temperature=self.kd_temperature, lambda_kd=self.lambda_kd) if self.teacher_model else None

        for features, labels in tqdm(data_loader, desc=f"è¨“ç·´ ({stage})"):
            features, labels = features.to(self.device), labels.to(self.device)
            
            optimizer.zero_grad()
            outputs = model(features)
            
            loss = criterion(outputs, labels)
            
            if self.teacher_model and (self.use_incremental or self.use_kd_only) and kd_loss_fn:
                with torch.no_grad():
                    teacher_outputs = self.teacher_model(features)
                teacher_padded = torch.zeros_like(outputs)
                if self.old_num_classes > 0:
                    # ä¿®æ”¹é»ï¼šåªå–æ•™å¸«æ¨¡å‹çš„å‰ old_num_classes å€‹ logits
                    teacher_outputs_old = teacher_outputs[:, :self.old_num_classes]
                    teacher_padded[:, :self.old_num_classes] = teacher_outputs_old
                kd_loss = kd_loss_fn(outputs, teacher_padded, labels, 
                                   old_classes=list(range(self.old_num_classes)))
                loss += kd_loss
            
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
        
        avg_loss = total_loss / len(data_loader)
        accuracy = 100 * correct / total
        return avg_loss, accuracy

    def evaluate(self, model, data_loader, criterion, monitor_old_classes=False):
        model.eval()
        total_loss = 0
        correct = 0
        total = 0
        old_correct = 0
        old_total = 0
        new_correct = 0
        new_total = 0
        
        confusion_matrix = {}
        
        with torch.no_grad():
            for features, labels in tqdm(data_loader, desc="è©•ä¼°"):
                features, labels = features.to(self.device), labels.to(self.device)
                outputs = model(features)
                
                loss = criterion(outputs, labels)
                total_loss += loss.item()
                
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
                
                if monitor_old_classes and self.old_animators:
                    old_indices = [self.data_manager.label_to_idx[anim] for anim in self.old_animators]
                    new_indices = [self.data_manager.label_to_idx[anim] for anim in self.new_animators]
                    
                    for i in range(labels.size(0)):
                        label = labels[i].item()
                        pred = predicted[i].item()
                        if label in old_indices:
                            old_total += 1
                            if label == pred:
                                old_correct += 1
                        if label in new_indices:
                            new_total += 1
                            if label == pred:
                                new_correct += 1
                        
                        label_key = self.data_manager.idx_to_label[label]
                        pred_key = self.data_manager.idx_to_label[pred]
                        confusion_matrix[(label_key, pred_key)] = confusion_matrix.get((label_key, pred_key), 0) + 1
        
        avg_loss = total_loss / len(data_loader)
        accuracy = 100 * correct / total
        old_accuracy = 100 * old_correct / old_total if old_total > 0 else 0
        new_accuracy = 100 * new_correct / new_total if new_total > 0 else 0
        
        print("\næ··æ·†çŸ©é™£çµ±è¨ˆ:")
        for (true_label, pred_label), count in sorted(confusion_matrix.items()):
            print(f"  {true_label} â†’ {pred_label}: {count} æ¬¡")
        
        return avg_loss, accuracy, old_accuracy, new_accuracy

    def train_model(self):
        print("ğŸ¯ é–‹å§‹è¨“ç·´æ··åˆæ¨¡å‹: EfficientNet-V2-S + é‚Šç·£ç‰¹å¾µ + TCN + BiLSTM...")
        
        train_loader, test_loader = self.create_data_loaders()
        num_classes = self.data_manager.get_num_classes()
        
        print(f"ğŸ¨ è­˜åˆ¥ {num_classes} å€‹åŸç•«å¸«: {list(self.data_manager.label_to_idx.keys())}")
        
        model, criterion = self.initialize_model(num_classes, load_pretrained=True)
        
        print("\nğŸ”§ è¨­ç½®å·®åˆ†å­¸ç¿’ç‡å„ªåŒ–å™¨...")
        
        temporal_body_params = [
            p for name, p in model.named_parameters() 
            if 'tcn.layers' in name or 'tcn.bilstm' in name
        ]
        
        head_params = [
            p for name, p in model.named_parameters() 
            if 'tcn.classifier' in name or 'feature_matching' in name or 'fusion_classifier' in name
        ]
        
        all_param_ids = set(id(p) for p in model.parameters())
        body_param_ids = set(id(p) for p in temporal_body_params)
        head_param_ids = set(id(p) for p in head_params)
        other_param_ids = all_param_ids - body_param_ids - head_param_ids
        other_params = [p for p in model.parameters() if id(p) in other_param_ids]
        if other_params:
            print(f"   - æ³¨æ„: æª¢æ¸¬åˆ° {len(other_params)} å€‹é¡å¤–åƒæ•¸ (å¦‚ fusion_weight), å°‡ä½¿ç”¨é ­éƒ¨å­¸ç¿’ç‡")
            head_params.extend(other_params)

        is_incremental_mode = self.use_incremental or self.use_kd_only
        
        lr_body = 1e-6 if is_incremental_mode else self.config.learning_rate / 100
        lr_heads = 1e-4 if is_incremental_mode else self.config.learning_rate

        optimizer = optim.AdamW([
            {'params': temporal_body_params, 'lr': lr_body},
            {'params': head_params, 'lr': lr_heads}
        ], weight_decay=0.01)

        print(f"   - æ¨¡å‹ä¸»é«” (TCN/BiLSTM) å­¸ç¿’ç‡: {lr_body}")
        print(f"   - åˆ†é¡é ­ (Classifiers/Matching) å­¸ç¿’ç‡: {lr_heads}")

        scheduler = optim.lr_scheduler.CosineAnnealingLR(
            optimizer, 
            T_max=self.config.num_epochs
        )
        
        best_accuracy = 0
        best_loss = float('inf')
        training_history = []
        total_epochs = self.config.num_epochs
        warmup_epochs = self.head_warmup_epochs if (self.use_incremental or self.use_kd_only) else 0
        
        for epoch in range(total_epochs):
            current_stage = 'head_warmup' if epoch < warmup_epochs else 'joint'
            print(f"\nğŸ“… Epoch {epoch+1}/{total_epochs} (ç•¶å‰éšæ®µ: {current_stage})")
            
            if current_stage == 'head_warmup':
                for g in optimizer.param_groups:
                    if len(g['params']) == len(temporal_body_params):
                         g['lr'] = 0
            elif current_stage == 'joint' and epoch == warmup_epochs:
                print(f"   - é€²å…¥ Joint è¨“ç·´ï¼Œæ¢å¾©ä¸»é«”å­¸ç¿’ç‡è‡³ {lr_body}")
                for g in optimizer.param_groups:
                    if len(g['params']) == len(temporal_body_params):
                         g['lr'] = lr_body
            
            train_loss, train_acc = self.train_epoch(model, train_loader, optimizer, criterion, stage=current_stage)
            test_loss, test_acc, old_acc, new_acc = self.evaluate(model, test_loader, criterion, monitor_old_classes=(self.use_incremental or self.use_kd_only))
            
            scheduler.step()
            
            print(f"ğŸ“Š è¨“ç·´æå¤±: {train_loss:.4f}, æº–ç¢ºç‡: {train_acc:.1f}%")
            print(f"ğŸ§ª æ¸¬è©¦æå¤±: {test_loss:.4f}, æº–ç¢ºç‡: {test_acc:.1f}%")
            
            if (self.use_incremental or self.use_kd_only) and old_acc > 0:
                print(f"   ğŸ›¡ï¸ èˆŠé¡: {old_acc:.1f}%", end="")
                if new_acc > 0:
                    print(f" | ğŸ†• æ–°é¡: {new_acc:.1f}%")
                else:
                    print()
                
                if current_stage == 'joint' and best_accuracy > 0 and old_acc < best_accuracy * 0.95:
                    print("âš ï¸ èˆŠé¡æº–ç¢ºç‡ä¸‹é™æ˜é¡¯ï¼Œè€ƒæ…®å¢åŠ  replay_ratio æˆ– lambda_kd")
            
            # Early Stopping é‚è¼¯
            current_metric = test_acc if self.early_stopping_monitor == 'test_acc' else test_loss
            is_improved = False
            
            if self.early_stopping_monitor == 'test_acc':
                if current_metric >= self.best_metric + self.early_stopping_min_delta:
                    is_improved = True
                    self.best_metric = current_metric
                    self.epochs_without_improvement = 0
                else:
                    self.epochs_without_improvement += 1
            else:  # test_loss
                if current_metric <= self.best_metric - self.early_stopping_min_delta:
                    is_improved = True
                    self.best_metric = current_metric
                    self.epochs_without_improvement = 0
                else:
                    self.epochs_without_improvement += 1
            
            if is_improved and test_acc > best_accuracy:
                best_accuracy = test_acc
                best_loss = test_loss
                save_as_teacher = self.use_incremental or self.use_kd_only
                self.save_model(model, num_classes, epoch, test_acc, save_as_teacher=save_as_teacher)
                print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (æº–ç¢ºç‡: {test_acc:.1f}%)")
            
            training_history.append({
                'epoch': epoch + 1,
                'train_loss': train_loss,
                'train_acc': train_acc,
                'test_loss': test_loss,
                'test_acc': test_acc,
                'old_acc': old_acc if (self.use_incremental or self.use_kd_only) else None,
                'new_acc': new_acc if (self.use_incremental or self.use_kd_only) else None,
                'learning_rate_body': optimizer.param_groups[0]['lr'],
                'learning_rate_head': optimizer.param_groups[1]['lr'],
                'stage': current_stage
            })
            
            # æª¢æŸ¥ Early Stopping
            if self.epochs_without_improvement >= self.early_stopping_patience:
                print(f"\nğŸ›‘ Early Stopping è§¸ç™¼: åœ¨ {self.early_stopping_patience} å€‹ epoch å…§æœªæ”¹å–„ {self.early_stopping_monitor}")
                print(f"   æœ€ä½³ {self.early_stopping_monitor}: {self.best_metric:.4f}")
                break
        
        self.save_exemplar_buffer(model)
        
        print(f"\nğŸ† è¨“ç·´å®Œæˆ! æœ€ä½³æ¸¬è©¦æº–ç¢ºç‡: {best_accuracy:.1f}%")
        return model, training_history
    
    def save_exemplar_buffer(self, model):
        print("\nğŸ’¾ ç”Ÿæˆ exemplar_buffer.json...")
        
        all_train_samples, _ = self.data_manager.get_fixed_split_samples()
        
        buffer_data = {}
        for feature_path, animator in all_train_samples:
            animator_idx = self.data_manager.label_to_idx[animator]
            
            if animator_idx not in buffer_data:
                buffer_data[animator_idx] = []
            
            buffer_data[animator_idx].append(feature_path)
        
        buffer_path = os.path.join(self.config.model_dir, 'exemplar_buffer.json')
        with open(buffer_path, 'w', encoding='utf-8') as f:
            json.dump(buffer_data, f, ensure_ascii=False, indent=2)
        
        total_samples = sum(len(paths) for paths in buffer_data.values())
        print(f"âœ… exemplar_buffer.json å·²ç”Ÿæˆ:")
        print(f"   ç¸½æ¨£æœ¬æ•¸: {total_samples}")
        print(f"   åŸç•«å¸«æ•¸: {len(buffer_data)}")
        for idx, paths in buffer_data.items():
            animator = self.data_manager.idx_to_label[idx]
            print(f"   {animator}: {len(paths)} å€‹æ¨£æœ¬")
        print(f"   ä¿å­˜è·¯å¾‘: {buffer_path}")
    
    def save_model(self, model, num_classes, epoch, accuracy, save_as_teacher=False):
        checkpoint = {
            'model_state_dict': model.state_dict(),
            'num_classes': num_classes,
            'epoch': epoch,
            'accuracy': accuracy,
            'label_mapping': {
                'label_to_idx': self.data_manager.label_to_idx,
                'idx_to_label': self.data_manager.idx_to_label
            },
            'config': self.config.__dict__,
            'model_type': 'hybrid_edge',
            'edge_dim': 64,
            'old_num_classes': self.old_num_classes,
            'new_animators': self.new_animators,
            'old_animators': self.old_animators
        }
        
        # ä¿å­˜ç‚º train_model.pthï¼ˆè¨“ç·´è¼¸å‡ºï¼‰
        train_model_path = os.path.join(self.config.model_dir, 'best_model.pth')
        torch.save(checkpoint, train_model_path)
        print(f"   ğŸ’¾ ä¿å­˜è¨“ç·´æ¨¡å‹: {train_model_path}")
        
        # â­ å¦‚æœæ˜¯å¢é‡å­¸ç¿’ï¼Œè‡ªå‹•æ›´æ–° best_model.pth
        # if save_as_teacher:
        #     best_model_path = os.path.join(self.config.model_dir, 'best_model.pth')
        #     torch.save(checkpoint, best_model_path)
        # print(f"   âœ… åŒæ­¥æ›´æ–° best_model.pthï¼ˆä¾›ä¸‹æ¬¡å¢é‡ä½¿ç”¨ï¼‰")
        # torch.save(checkpoint, os.path.join(self.config.model_dir, 'latest_model.pth'))

        
        # ç„¡è«–å¦‚ä½•éƒ½ä¿å­˜ best å’Œ latest
        # torch.save(checkpoint, os.path.join(self.config.model_dir, 'best_model.pth'))
        # torch.save(checkpoint, os.path.join(self.config.model_dir, 'latest_model.pth'))