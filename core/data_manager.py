import os
import json
import numpy as np
from collections import defaultdict
import cv2
import re

def detect_aspect_ratio(video_path):
    """æª¢æ¸¬å½±ç‰‡æ¯”ä¾‹(ç¨ç«‹å‡½æ•¸)"""
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        return "unknown"
    
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    cap.release()
    
    if width == 0 or height == 0:
        return "unknown"
    
    aspect_ratio = width / height
    
    if abs(aspect_ratio - 16/9) < 0.1:
        return "16:9"
    elif abs(aspect_ratio - 4/3) < 0.1:
        return "4:3"
    elif abs(aspect_ratio - 1) < 0.1:
        return "1:1"
    elif abs(aspect_ratio - 936/480) < 0.1:
        return "936:480"
    elif abs(aspect_ratio - 1136/480) < 0.1:
        return "1136:480"
    else:
        return "other"

def extract_base_video_name(filename):
    """
    æå–å½±ç‰‡çš„åŸºç¤åç¨±,å»é™¤ç‰‡æ®µç·¨è™Ÿ
    ä¾‹å¦‚:
    - yutaka_nakamura_123_001.mp4 -> yutaka_nakamura_123
    - video_part1.mp4 -> video
    - animation_01.mp4 -> animation
    """
    # ç§»é™¤å‰¯æª”å
    name = os.path.splitext(filename)[0]
    
    # å˜—è©¦åŒ¹é…å¸¸è¦‹çš„ç‰‡æ®µæ¨¡å¼
    patterns = [
        r'(.+)_\d{3}$',           # name_001, name_002
        r'(.+)_part\d+$',         # name_part1, name_part2
        r'(.+)_segment\d+$',      # name_segment1
        r'(.+)-\d+$',             # name-1, name-2
        r'(.+)_\d+$',             # name_1, name_2
    ]
    
    for pattern in patterns:
        match = re.match(pattern, name, re.IGNORECASE)
        if match:
            return match.group(1)
    
    # å¦‚æœæ²’æœ‰åŒ¹é…åˆ°,è¿”å›åŸåç¨±
    return name

# ### æ–°å¢ï¼šæª¢æŸ¥å½±ç‰‡æœ‰æ•ˆæ€§ï¼ˆé•·åº¦ 2-15sï¼‰
def is_valid_video(video_path, min_duration=2, max_duration=15):
    """æª¢æŸ¥å½±ç‰‡æ˜¯å¦æœ‰æ•ˆï¼ˆé•·åº¦åœ¨ min-max ä¹‹é–“ï¼‰"""
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        return False
    
    fps = cap.get(cv2.CAP_PROP_FPS)
    frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    cap.release()
    
    if fps <= 0 or frames <= 0:
        return False
    
    duration = frames / fps
    return min_duration <= duration <= max_duration

class DataManager:
    def __init__(self, config):
        self.config = config
        self.metadata_file = os.path.join(config.feature_dir, 'metadata.json')
        self.load_metadata()
        # ### æ–°å¢ï¼šåˆå§‹åŒ–å¾Œè‡ªå‹•æª¢æŸ¥/æ›´æ–°ï¼ˆå¯é¸ï¼Œè¨­ force=False é¿å…æ¯æ¬¡è·‘ï¼‰
        self.update_metadata_valid_only(force=False)  # force=True å¼·åˆ¶é‡æƒ
    
    def load_metadata(self):
        """è¼‰å…¥å…ƒæ•¸æ“š"""
        if os.path.exists(self.metadata_file):
            with open(self.metadata_file, 'r', encoding='utf-8') as f:
                self.metadata = json.load(f)
        else:
            self.metadata = {
                'animators': {},
                'video_count': 0,
                'feature_count': 0,
                'last_updated': None,
                'video_groups': {},  # æ–°å¢: è¨˜éŒ„å½±ç‰‡åˆ†çµ„ä¿¡æ¯
                'fixed_split': {}  # æ–°å¢: å›ºå®šçš„è¨“ç·´/æ¸¬è©¦åˆ†å‰²
            }
        
        # æ¨™ç±¤æ˜ å°„
        self.label_to_idx = {}
        self.idx_to_label = {}
        self._update_label_mapping()
    
    # ### æ–°å¢ï¼šä¿®æ­£ metadataï¼Œåªä¿ç•™æœ‰æ•ˆå½±ç‰‡
    def update_metadata_valid_only(self, force=False):
        """æ›´æ–° metadataï¼Œåªä¿ç•™æœ‰æ•ˆå½±ç‰‡ï¼ˆé•·åº¦ 2-15s + å­˜åœ¨ç‰¹å¾µï¼‰"""
        if not force and self.metadata.get('last_valid_update'):  # å·²æ›´æ–°éï¼Œè·³é
            print("ğŸ“Š metadata å·²ç‚ºæœ‰æ•ˆå½±ç‰‡æ›´æ–°éï¼Œè·³é")
            return
        
        print("ğŸ”„ æ›´æ–° metadata: åªä¿ç•™æœ‰æ•ˆå½±ç‰‡...")
        min_duration = getattr(self.config, 'min_video_duration', 2)
        max_duration = getattr(self.config, 'max_video_duration', 15)
        
        updated_animators = {}
        total_valid_videos = 0
        removed_count = 0
        
        for animator, info in self.metadata['animators'].items():
            valid_video_paths = []
            valid_feature_files = []
            valid_aspect_ratios = {}
            valid_video_groups = {}
            
            for i, (video_path, feature_file) in enumerate(zip(info['video_paths'], info['feature_files'])):
                video_name = os.path.basename(video_path)
                
                # æª¢æŸ¥ 1: å½±ç‰‡æœ‰æ•ˆï¼ˆé•·åº¦ï¼‰
                if not is_valid_video(video_path, min_duration, max_duration):
                    removed_count += 1
                    continue
                
                # æª¢æŸ¥ 2: ç‰¹å¾µæª”æ¡ˆå­˜åœ¨
                feature_path = os.path.join(self.config.feature_dir, feature_file)
                if not os.path.exists(feature_path):
                    removed_count += 1
                    continue
                
                # ä¿ç•™
                valid_video_paths.append(video_path)
                valid_feature_files.append(feature_file)
                
                # é‡æ–°ç®— aspectï¼ˆå¦‚æœèˆŠçš„ unknownï¼Œé‡ç®—ï¼‰
                aspect = info['aspect_ratios'].get(video_name, "unknown")
                if aspect == "unknown":
                    aspect = detect_aspect_ratio(video_path)
                valid_aspect_ratios[video_name] = aspect
                
                # ä¿ç•™ group
                base_name = extract_base_video_name(video_name)
                valid_video_groups[video_name] = base_name
            
            # æ›´æ–° info
            updated_info = {
                'video_count': len(valid_video_paths),
                'video_paths': valid_video_paths,
                'feature_files': valid_feature_files,
                'aspect_ratios': valid_aspect_ratios,
                'video_groups': valid_video_groups,
                'added_date': info.get('added_date')  # ä¿ç•™èˆŠè³‡è¨Š
            }
            updated_animators[animator] = updated_info
            total_valid_videos += len(valid_video_paths)
        
        # æ›´æ–°ç¸½è¨ˆ
        self.metadata['animators'] = updated_animators
        self.metadata['video_count'] = total_valid_videos
        self.metadata['feature_count'] = total_valid_videos  # å‡è¨­æ¯å€‹æœ‰æ•ˆéƒ½æœ‰ .npy
        self.metadata['last_valid_update'] = str(np.datetime64('now'))  # æ¨™è¨˜å·²æ›´æ–°
        
        # é‡æ–°æ›´æ–° label_mappingï¼ˆè¬ä¸€æœ‰ç©º animatorï¼‰
        self._update_label_mapping()
        
        self.save_metadata()
        
        print(f"âœ… æ›´æ–°å®Œæˆ: ä¿ç•™ {total_valid_videos} å€‹æœ‰æ•ˆå½±ç‰‡ï¼Œç§»é™¤ {removed_count} å€‹ç„¡æ•ˆ")
        print(f"ğŸ“Š æ–° video_count: {total_valid_videos} (èˆ‡ç‰¹å¾µæª”æ¡ˆä¸€è‡´)")
    
    def _update_label_mapping(self):
        """å¾å…ƒæ•¸æ“šæ›´æ–°æ¨™ç±¤æ˜ å°„"""
        all_animators = sorted(self.metadata['animators'].keys())
        self.label_to_idx = {animator: idx for idx, animator in enumerate(all_animators)}
        self.idx_to_label = {idx: animator for animator, idx in self.label_to_idx.items()}
    
    def save_metadata(self):
        """ä¿å­˜å…ƒæ•¸æ“š"""
        with open(self.metadata_file, 'w', encoding='utf-8') as f:
            json.dump(self.metadata, f, ensure_ascii=False, indent=2)
    
    def scan_data_directory(self, data_root):
        """æƒææ•¸æ“šç›®éŒ„,ç™¼ç¾æ–°çš„åŸç•«å¸«å’Œå½±ç‰‡"""
        print("ğŸ” æƒææ•¸æ“šç›®éŒ„...")
        
        existing_animators = set(self.metadata['animators'].keys())
        new_animators = set()
        all_samples = []
        
        for root, dirs, files in os.walk(data_root):
            animator = os.path.basename(root)
            video_files = [f for f in files if f.lower().endswith(('.mp4', '.avi', '.mov', '.mkv', '.flv'))]
            
            if animator and video_files:
                if animator not in existing_animators:
                    new_animators.add(animator)
                    print(f"ğŸ¯ ç™¼ç¾æ–°åŸç•«å¸«: {animator}")
                
                # æ”¶é›†æ‰€æœ‰æ¨£æœ¬
                for file in video_files:
                    video_path = os.path.join(root, file)
                    all_samples.append((video_path, animator))
        
        print(f"ğŸ“Š ç™¼ç¾ {len(new_animators)} å€‹æ–°åŸç•«å¸«, {len(all_samples)} å€‹å½±ç‰‡")
        return list(new_animators), all_samples
    
    def register_animator(self, animator, video_paths):
        """è¨»å†ŠåŸç•«å¸«å’Œå½±ç‰‡"""
        if animator not in self.metadata['animators']:
            self.metadata['animators'][animator] = {
                'video_count': 0,
                'video_paths': [],
                'feature_files': [],
                'aspect_ratios': {},
                'video_groups': {},  # æ–°å¢: è¨˜éŒ„æ¯å€‹å½±ç‰‡å±¬æ–¼å“ªå€‹çµ„
                'added_date': None
            }
        
        # ### ä¿®æ”¹ï¼šè¨»å†Šå‰éæ¿¾æœ‰æ•ˆå½±ç‰‡
        valid_paths = [p for p in video_paths if is_valid_video(p)]  # åªè¨»å†Šæœ‰æ•ˆ
        print(f"è¨»å†Š {animator}: {len(valid_paths)}/{len(video_paths)} æœ‰æ•ˆå½±ç‰‡")
        
        for video_path in valid_paths:
            if video_path not in self.metadata['animators'][animator]['video_paths']:
                video_name = os.path.basename(video_path)
                feature_file = f"{os.path.splitext(video_name)[0]}.npy"
                
                # æå–åŸºç¤å½±ç‰‡åç¨±
                base_name = extract_base_video_name(video_name)
                
                # â­ ç›´æ¥ä½¿ç”¨ç¨ç«‹å‡½æ•¸æª¢æ¸¬æ¯”ä¾‹,ä¸è¼‰å…¥æ¨¡å‹
                aspect_ratio = detect_aspect_ratio(video_path)
                
                self.metadata['animators'][animator]['video_paths'].append(video_path)
                self.metadata['animators'][animator]['feature_files'].append(feature_file)
                self.metadata['animators'][animator]['aspect_ratios'][video_name] = aspect_ratio
                self.metadata['animators'][animator]['video_groups'][video_name] = base_name
                self.metadata['animators'][animator]['video_count'] += 1
                self.metadata['video_count'] += 1
        
        self.metadata['last_updated'] = str(np.datetime64('now'))
        self._update_label_mapping()
        self.save_metadata()
    
    def get_all_feature_samples(self):
        """ç²å–æ‰€æœ‰ç‰¹å¾µæ¨£æœ¬"""
        feature_samples = []
        for animator, info in self.metadata['animators'].items():
            for feature_file in info['feature_files']:
                feature_path = os.path.join(self.config.feature_dir, feature_file)
                if os.path.exists(feature_path):
                    feature_samples.append((feature_path, animator))
        
        self.metadata['feature_count'] = len(feature_samples)
        self.save_metadata()
        
        return feature_samples
    def get_fixed_split_video_samples(self):
        """
        æ ¹æ“šå›ºå®šåˆ†å‰²ç²å–è¨“ç·´/æ¸¬è©¦çš„ **å½±ç‰‡æ¨£æœ¬**
        
        Returns:
            (train_samples, test_samples): å…©å€‹åˆ—è¡¨,æ¯å€‹å…ƒç´ ç‚º (video_path, animator)
        """
        if not self.metadata.get('fixed_split'):
            raise ValueError("âŒ å°šæœªå‰µå»ºå›ºå®šåˆ†å‰²,è«‹å…ˆé‹è¡Œ create_fixed_train_test_split()")

        fixed_split = self.metadata['fixed_split']
        train_groups_dict = fixed_split['train_groups']
        test_groups_dict = fixed_split['test_groups']
        
        train_samples = []
        test_samples = []

        for animator, info in self.metadata['animators'].items():
            video_groups = info.get('video_groups', {})
            
            # ç²å–è©²å‹•ç•«å¸«çš„è¨“ç·´/æ¸¬è©¦çµ„
            train_groups = set(train_groups_dict.get(animator, []))
            test_groups = set(test_groups_dict.get(animator, []))
            
            for video_path in info['video_paths']:
                video_name = os.path.basename(video_path)
                group_id = video_groups.get(video_name)
                
                # çµ„åˆ animator + group_id ä½œç‚ºå…¨å±€å”¯ä¸€çµ„æ¨™è­˜
                global_group_id = f"{animator}_{group_id}"

                if global_group_id in train_groups:
                    train_samples.append((video_path, animator))
                elif global_group_id in test_groups:
                    test_samples.append((video_path, animator))
                # æ³¨æ„ï¼šé€™è£¡æˆ‘å€‘å¿½ç•¥äº†æœªè¢«åˆ†çµ„çš„æ–°å½±ç‰‡ï¼Œå› ç‚ºå…¨é‡è¨“ç·´æ™‚æ‡‰è©²å…ˆåˆ†å‰²å¥½æ‰€æœ‰æ•¸æ“š
        
        return train_samples, test_samples
    def get_feature_samples_with_groups(self):
        """
        ç²å–æ‰€æœ‰ç‰¹å¾µæ¨£æœ¬,ä¸¦é™„å¸¶åˆ†çµ„ä¿¡æ¯
        è¿”å›: [(feature_path, animator, group_id), ...]
        """
        feature_samples = []
        for animator, info in self.metadata['animators'].items():
            video_groups = info.get('video_groups', {})
            
            for i, feature_file in enumerate(info['feature_files']):
                feature_path = os.path.join(self.config.feature_dir, feature_file)
                if os.path.exists(feature_path):
                    # å¾ç‰¹å¾µæ–‡ä»¶ååæ¨åŸå§‹å½±ç‰‡å
                    video_name = feature_file.replace('.npy', '')
                    
                    # æ‰¾åˆ°å°æ‡‰çš„å½±ç‰‡å(å¸¶å‰¯æª”å)
                    matching_video = None
                    for video_path in info['video_paths']:
                        if os.path.splitext(os.path.basename(video_path))[0] == video_name:
                            matching_video = os.path.basename(video_path)
                            break
                    
                    # ç²å–åˆ†çµ„ID
                    if matching_video and matching_video in video_groups:
                        group_id = video_groups[matching_video]
                    else:
                        # å¦‚æœæ²’æœ‰åˆ†çµ„ä¿¡æ¯,ä½¿ç”¨ç‰¹å¾µæ–‡ä»¶åä½œç‚ºå”¯ä¸€ID
                        group_id = video_name
                    
                    # çµ„åˆ animator + group_id ä½œç‚ºå…¨å±€å”¯ä¸€çµ„æ¨™è­˜
                    global_group_id = f"{animator}_{group_id}"
                    
                    feature_samples.append((feature_path, animator, global_group_id))
        
        return feature_samples
    
    def get_num_classes(self):
        """ç²å–ç•¶å‰é¡åˆ¥æ•¸é‡"""
        return len(self.label_to_idx)
    
    def get_aspect_ratio_stats(self):
        """ç²å–æ¯”ä¾‹çµ±è¨ˆ"""
        aspect_ratio_counts = {}
        for animator, info in self.metadata['animators'].items():
            for video_name, ratio in info['aspect_ratios'].items():
                if ratio not in aspect_ratio_counts:
                    aspect_ratio_counts[ratio] = 0
                aspect_ratio_counts[ratio] += 1
        return aspect_ratio_counts
    
    def create_fixed_train_test_split(self, train_ratio=0.8, force_resplit=False):
        """
        å‰µå»ºå›ºå®šçš„è¨“ç·´/æ¸¬è©¦é›†åˆ†å‰²
        
        Args:
            train_ratio: è¨“ç·´é›†æ¯”ä¾‹
            force_resplit: æ˜¯å¦å¼·åˆ¶é‡æ–°åˆ†å‰²(è­¦å‘Š:æœƒæ”¹è®Šå·²æœ‰çš„åˆ†å‰²)
        """
        # æª¢æŸ¥æ˜¯å¦å·²æœ‰å›ºå®šåˆ†å‰²
        if self.metadata.get('fixed_split') and not force_resplit:
            print("âœ… ä½¿ç”¨å·²å­˜åœ¨çš„å›ºå®šè¨“ç·´/æ¸¬è©¦åˆ†å‰²")
            return
        
        if force_resplit:
            print("âš ï¸  è­¦å‘Š: å¼·åˆ¶é‡æ–°åˆ†å‰²æœƒæ”¹è®ŠåŸæœ‰çš„è¨“ç·´/æ¸¬è©¦é›†!")
        
        print("ğŸ”’ å‰µå»ºå›ºå®šçš„è¨“ç·´/æ¸¬è©¦é›†åˆ†å‰²...")
        
        # ç²å–å¸¶åˆ†çµ„ä¿¡æ¯çš„æ¨£æœ¬
        all_samples_with_groups = self.get_feature_samples_with_groups()
        
        if not all_samples_with_groups:
            print("âŒ æ²’æœ‰ç‰¹å¾µæ¨£æœ¬,ç„¡æ³•å‰µå»ºåˆ†å‰²")
            return
        
        # æŒ‰åŸç•«å¸«å’Œå½±ç‰‡çµ„åˆ†çµ„
        animator_video_groups = {}
        for feature_path, animator, group_id in all_samples_with_groups:
            if animator not in animator_video_groups:
                animator_video_groups[animator] = {}
            
            if group_id not in animator_video_groups[animator]:
                animator_video_groups[animator][group_id] = []
            
            animator_video_groups[animator][group_id].append(feature_path)
        
        # å‰µå»ºå›ºå®šåˆ†å‰²
        fixed_split = {
            'train_groups': {},  # {animator: [group_ids]}
            'test_groups': {},   # {animator: [group_ids]}
            'created_at': str(np.datetime64('now')),
            'train_ratio': train_ratio
        }
        
        print("\nğŸ“Š åˆ†å‰²çµæœ:")
        for animator, video_groups in animator_video_groups.items():
            group_ids = list(video_groups.keys())
            
            # ä½¿ç”¨å›ºå®šçš„éš¨æ©Ÿç¨®å­ç¢ºä¿å¯é‡ç¾
            rng = np.random.RandomState(42)
            rng.shuffle(group_ids)
            
            # æŒ‰çµ„åˆ†å‰²
            num_groups = len(group_ids)
            train_group_count = max(1, int(num_groups * train_ratio))
            
            train_groups = group_ids[:train_group_count]
            test_groups = group_ids[train_group_count:]
            
            fixed_split['train_groups'][animator] = train_groups
            fixed_split['test_groups'][animator] = test_groups
            
            # çµ±è¨ˆç‰‡æ®µæ•¸
            train_count = sum(len(video_groups[g]) for g in train_groups)
            test_count = sum(len(video_groups[g]) for g in test_groups)
            
            print(f"  {animator}:")
            print(f"    å½±ç‰‡çµ„: {num_groups} å€‹ (è¨“ç·´ {len(train_groups)}, æ¸¬è©¦ {len(test_groups)})")
            print(f"    ç‰‡æ®µæ•¸: è¨“ç·´ {train_count}, æ¸¬è©¦ {test_count}")
        
        # ä¿å­˜å›ºå®šåˆ†å‰²
        self.metadata['fixed_split'] = fixed_split
        self.save_metadata()
        
        print("\nğŸ”’ å›ºå®šåˆ†å‰²å·²ä¿å­˜åˆ° metadata.json")
    
    def get_fixed_split_samples(self):
        """
        æ ¹æ“šå›ºå®šåˆ†å‰²ç²å–è¨“ç·´/æ¸¬è©¦æ¨£æœ¬
        
        Returns:
            (train_samples, test_samples): å…©å€‹åˆ—è¡¨,æ¯å€‹å…ƒç´ ç‚º (feature_path, animator)
        """
        if not self.metadata.get('fixed_split'):
            raise ValueError("âŒ å°šæœªå‰µå»ºå›ºå®šåˆ†å‰²,è«‹å…ˆé‹è¡Œ create_fixed_train_test_split()")
        
        fixed_split = self.metadata['fixed_split']
        train_groups_dict = fixed_split['train_groups']
        test_groups_dict = fixed_split['test_groups']
        train_ratio = fixed_split.get('train_ratio', 0.8)
        
        # ç²å–ç•¶å‰æ‰€æœ‰æ¨£æœ¬
        all_samples_with_groups = self.get_feature_samples_with_groups()
        
        # æŒ‰åŸç•«å¸«å’Œçµ„åˆ†é¡
        animator_group_samples = {}
        for feature_path, animator, group_id in all_samples_with_groups:
            if animator not in animator_group_samples:
                animator_group_samples[animator] = {}
            
            if group_id not in animator_group_samples[animator]:
                animator_group_samples[animator][group_id] = []
            
            animator_group_samples[animator][group_id].append((feature_path, animator))
        
        # æ ¹æ“šå›ºå®šåˆ†å‰²æ”¶é›†æ¨£æœ¬
        train_samples = []
        test_samples = []
        new_groups_by_animator = {}  # è¨˜éŒ„æ¯å€‹åŸç•«å¸«çš„æ–°å¢çµ„
        
        for animator, group_samples in animator_group_samples.items():
            # ç²å–è©²åŸç•«å¸«çš„å›ºå®šåˆ†å‰²
            train_groups = train_groups_dict.get(animator, [])
            test_groups = test_groups_dict.get(animator, [])
            
            # æ”¶é›†æ–°å¢çš„çµ„
            new_groups = []
            
            for group_id, samples in group_samples.items():
                if group_id in train_groups:
                    train_samples.extend(samples)
                elif group_id in test_groups:
                    test_samples.extend(samples)
                else:
                    # æ–°å¢çš„çµ„
                    new_groups.append((group_id, samples))
            
            if new_groups:
                new_groups_by_animator[animator] = new_groups
        
        # å°æ–°å¢çµ„é€²è¡Œåˆ†å‰²
        if new_groups_by_animator:
            print(f"\nğŸ†• ç™¼ç¾æ–°å½±ç‰‡çµ„,æŒ‰æ¯”ä¾‹ {train_ratio:.0%}/{(1-train_ratio):.0%} åˆ†å‰²:")
            
            for animator, new_groups in new_groups_by_animator.items():
                # ä½¿ç”¨å›ºå®šéš¨æ©Ÿç¨®å­ + åŸç•«å¸«åç¨±ç¢ºä¿å¯é‡ç¾
                seed = hash(animator) % (2**32)
                rng = np.random.RandomState(seed)
                
                # æ‰“äº‚æ–°çµ„
                rng.shuffle(new_groups)
                
                # æŒ‰æ¯”ä¾‹åˆ†å‰²
                num_new_groups = len(new_groups)
                train_count = max(1, int(num_new_groups * train_ratio)) if num_new_groups > 1 else 1
                
                new_train_groups = new_groups[:train_count]
                new_test_groups = new_groups[train_count:]
                
                # æ›´æ–°å›ºå®šåˆ†å‰²
                if animator not in fixed_split['train_groups']:
                    fixed_split['train_groups'][animator] = []
                if animator not in fixed_split['test_groups']:
                    fixed_split['test_groups'][animator] = []
                
                # æ·»åŠ åˆ°è¨“ç·´é›†
                train_sample_count = 0
                for group_id, samples in new_train_groups:
                    train_samples.extend(samples)
                    fixed_split['train_groups'][animator].append(group_id)
                    train_sample_count += len(samples)
                
                # æ·»åŠ åˆ°æ¸¬è©¦é›†
                test_sample_count = 0
                for group_id, samples in new_test_groups:
                    test_samples.extend(samples)
                    fixed_split['test_groups'][animator].append(group_id)
                    test_sample_count += len(samples)
                
                print(f"  {animator}:")
                print(f"    æ–°å¢å½±ç‰‡çµ„: {num_new_groups} å€‹ (è¨“ç·´ {len(new_train_groups)}, æ¸¬è©¦ {len(new_test_groups)})")
                print(f"    æ–°å¢ç‰‡æ®µæ•¸: è¨“ç·´ {train_sample_count}, æ¸¬è©¦ {test_sample_count}")
            
            # ä¿å­˜æ›´æ–°å¾Œçš„åˆ†å‰²
            self.save_metadata()
            print("\nğŸ”’ æ–°æ•¸æ“šçš„åˆ†å‰²å·²ä¿å­˜åˆ° metadata.json")
        
        return train_samples, test_samples